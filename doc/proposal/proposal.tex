%----------------------------------------------------------------------

% Template for TECHNICAL REPORTS at Inst. for Computer Graphics

% and Vision (ICG), Graz University of Technology, Austria:

% style file 'techrep_icg.sty'

%

% author:  Pierre Elbischger

% email:   pierre.elibschger@icg.tu-graz.ac.at

% created: 13.11.2003

% last revision: 25.11.2003

%----------------------------------------------------------------------

% The template contains a number of LaTeX commands of the form :

%

% \command{xyz}

%

% In order to complete this abstract, fill in the blank fields between

% the curly braces or replace already filled in fields with the

% requested information.

%

% e.g. in order to add an abstract title, replace

% \title{}    with   \title{Evidence of Solitons in Tedium Diboride}

%

% The \author and \address commands can take an optional label

% in square brackets of the form :

%

% \command[label]{}

%

% The text of the abstract should be inserted between the two commands

% \begin{abstract} and \end{abstract}.

%

% Please leave all commands in place even if you don't fill them in.

%

%----------------------------------------------------------------------

% Do not alter the following two lines

\documentclass[12pt,a4paper]{article}               % I'm using a double-sided book style

      

\usepackage{techrep_icg}


% package 'graphicx' is automatically included depending on the

%   used compiler (latex, pdflatex), don't include it!!!



\begin{document}

%----------------------------------------------------------------------



%\reportnr{xxx}               % Number of the technical report

\title{Proposal} % Title of technical report

\subtitle{Camera relocalization using regression random forest} % Subtitle of technical report (use small letters only)

\repcity{Graz}            % City where the report was created

\repdate{\today}          % Date of creation

\keywords{Report, Technical report, template, ICG} % keywords that appear below the abstract



%----------------------------------------------------------------------

% List of authors

%

% List each author using a separate \author{} command

% If there is more than one author address, add a label to each author

% of the form \author[label]{name}.  This label should be identical to

% the corresponding label provided with the \address command

% N.B. It is not possible to link an author to more than one address.

%

\author[ICG]{Thomas Pietsch 0930557}
\author[ICG]{Bernhard Rapp 0830250}


%----------------------------------------------------------------------

% List of addresses

%

% If there is more than one address, list each using a separate

% \address command using a label to link it to the respective author

% as described above


\newcommand{\TUGn}{Graz University of Technology}

\address[ICG]{Inst. for Computer Graphics and Vision \\ \TUGn, Austria}



%----------------------------------------------------------------------

% Information about the contact author

% if \contact is not defined (uncommented) or empty, the contact

%  information on the title page is suppressed.



% Name of contact

\contact{Thomas Pietsch}

% Email address of contact - do not use any LaTeX formatting here

\contactemail{thomas.pietsch@student.tugraz.at}



%----------------------------------------------------------------------

% Do not alter the following line



\begin{abstract}



Replace this text with your abstract.



%----------------------------------------------------------------------

% Do not alter the following two lines

\end{abstract}






\section{Project Proposal}

\subsection{Research of SOTA} % (fold)
\label{sub:research_of_sota}

% subsection research_of_sota (end)


\subsection{What method will get implemented?} % (fold)
\label{sub:what_method_will_get_implemented_}

\subsubsection*{Regression Forest} % (fold)
\label{ssub:regression_forest}

First a regression forest based on the Piotr Dollar toolbox \cite{piotr} will be implemented. The Matlab code for the Piotr Dollar toolbox is readily available and we will adapt the random classification forest to create a regression forest. Therefore the split function and output has to be modified.

Secondly the implementation itself should be evaluated, to make a statement to the general performance of the implementation.

After that the implementation should be used for camera relocalization. Again the dataset should be evaluated. Here not only the evaluation described below is used, but also own dataset. The aim of this work is to show negative examples and find scenarios where the introduced method \cite{shotton} doesn't work as presented.

The implementation of the regression forest can be evaluated using standard regression benchmarks from
\href{https://archive.ics.uci.edu/ml/datasets.html?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table}{https://archive.ics.uci.edu}

% subsubsection regression_forest (end)

\subsubsection{Camera Relocalization} % (fold)
\label{ssub:camera_relocalization}

The regression forest will now be used for the task of camera relocalization. To achieve this the method by Shotton et al. \cite{shotton} will be implemented.

This method uses a weak learner approach. The regression tree is evaluated by starting at the root node and descend to a leaf by repeatedly evaluating:

\begin{eqnarray}\label{eqn:weaklearner}
  h(\mathbf{p};\mathbf{\theta}_n) = [ f_{\phi_n}(\mathbf{p}) \geq \tau_n ]
\end{eqnarray}


Where $\mathbf{p}$ denotes the 2D pixel location in an image, $\tau$ a threshold, and n the index of a node in the tree. $f_{\phi}$ is a feature response function. Each leaf node stores a distribution $P_{l}(\mathbf{m})$ with $\mathbf{m} \in \mathbb{R}^3$ being the scene's 3D coordinates in world space.

The following feature response functions were defined:

\begin{eqnarray}
  f_{\phi}^{depth}(\mathbf{p}) = D(\mathbf{p} + \frac{\mathbf{\delta_1}}{D(\mathbf{p})}) - D(\mathbf{p} + \frac{\mathbf{\delta_2}}{D(\mathbf(p))})
\end{eqnarray}
\begin{eqnarray}
  f_{\phi}^{da-rgb}(\mathbf{p}) = I(\mathbf{p} + \frac{\mathbf{\delta_1}}{D(\mathbf{p})},c_1) - I(\mathbf{p} + \frac{\mathbf{\delta_2}}{D(\mathbf(p))},c_2)
\end{eqnarray}

$\mathbf{\delta}$ indicates a 2D offset, $D(\mathbf{p})$ a depth pixel lookup, and $I(\mathbf{p},c)$ indicates an RGB pixel lookup in channel $c$.

The scene coordinate labels are simply defined as the scene world positions $\mathbf{m}$:

\begin{eqnarray*}
  \mathbf{m} = Hx
\end{eqnarray*}

With this labeling the forest can be grown using the standard greedy forest training algorithm. At each node a weak lerner parameter $\theta$ is sampled at random and evaluated by equation (\ref{eqn:weaklearner}). This leaves two subsets which can be evaluated as follows:


\begin{eqnarray}
  Q(S_n,\theta) = V(S_n) - \sum_{d\in\{L,R\}}{\frac{|S_n^d(\theta)|}{|S_n|}V(S_n^d(\theta))}
\end{eqnarray}

\begin{eqnarray}
  V(S) = \frac{1}{|S|} \sum_{(\mathbf{p},\mathbf{m}) \in S}{||\mathbf{m} - \mathbf{\bar m}||_2^2}
\end{eqnarray}

With this regression forest it is now possible to associate scene coordinates with any 2D image pixel. This information can be used to estimate the camera location and orientation by minimizing the energy over the camera pose matrix H.

\begin{eqnarray}
  H^{*} = arg\min_H E(H)
\end{eqnarray} 

\begin{eqnarray}
  E(H) = \sum_{i \in \mathit{I}}{\rho (\min_{m \in \mathit{M}_i}||\mathbf{m} -Hx_i||_2)} = \sum_{i \in \mathit{I}}{e_i(H)}
\end{eqnarray}

This energy is optimized using an adapted version of preemptive RANSAC \cite{ransac}.

% subsubsection camera_relocalization (end)

% subsection what_method_will_get_implemented_ (end)

\subsection{How can the method be evaluated?} % (fold)
\label{sub:how_can_the_method_be_evaluated_}

Shotton et al. \cite{shotton} provide several datasets which can be used to evaluate our implementation. Their main metric was the percentage of frames for which the `correct' camera pose is inferred. The parameter settings of Shotton et al. were fixed and a variation of those could be evaluated as well. Further we could create our own datasets using Kinect Fusion \cite{izadi_fusion} \cite{newcombe_fusion} to test the limits of the approach.



% subsection how_can_the_method_be_evaluated_ (end)


% ============================================================
% Bibliography
% ============================================================
\clearpage
\renewcommand{\leftmark}{}



\bibliographystyle{plain}
%\addcontentsline{toc}{chapter}{Bibliography}
%\bibliographystyle{plain}
\bibliography{./bibtex}

\end{document}

%----------------------------------------------------------------------

